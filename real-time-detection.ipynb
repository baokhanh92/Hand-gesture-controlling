{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from phue import Bridge\n",
    "from soco import SoCo\n",
    "import pygame\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Settings\n",
    "prediction = ''\n",
    "action = ''\n",
    "score = 0\n",
    "img_counter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Volume(object):\n",
    "    def __init__(self):\n",
    "        self.level = .5\n",
    "\n",
    "    def increase(self, amount):\n",
    "        self.level += amount\n",
    "        print(f'New level is: {self.level}')\n",
    "\n",
    "    def decrease(self, amount):\n",
    "        self.level -= amount\n",
    "        print(f'New level is: {self.level}')\n",
    "\n",
    "\n",
    "vol = Volume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images = False\n",
    "smart_home = True\n",
    "\n",
    "gesture_names = {0: 'Fist',\n",
    "                 1: 'L',\n",
    "                 2: 'Okay',\n",
    "                 3: 'Palm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('hand-gesture.h5')\n",
    "\n",
    "def predict_rgb_image(img):\n",
    "    result = gesture_names[model.predict_classes(img)[0]]\n",
    "    print(result)\n",
    "    return (result)\n",
    "\n",
    "def predict_rgb_image_vgg(image):\n",
    "    image = np.array(image, dtype='float32')\n",
    "    image /= 255\n",
    "    pred_array = model.predict(image)\n",
    "    print(f'pred_array: {pred_array}')\n",
    "    result = gesture_names[np.argmax(pred_array)]\n",
    "    print(f'Result: {result}')\n",
    "    print(max(pred_array[0]))\n",
    "    score = float(\"%0.2f\" % (max(pred_array[0]) * 100))\n",
    "    print(result)\n",
    "    return result, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "cap_region_x_begin = 0.5  # start point/total width\n",
    "cap_region_y_end = 0.8  # start point/total width\n",
    "threshold = 60  # binary threshold\n",
    "blurValue = 41  # GaussianBlur parameter\n",
    "bgSubThreshold = 50\n",
    "learningRate = 0\n",
    "\n",
    "# variableslt\n",
    "isBgCaptured = 1  # bool, whether the background captured\n",
    "triggerSwitch = False  # if true, keyboard simulator works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(frame):\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "    fgmask = backSub.apply(frame)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=fgmask)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-141a3dc15f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# press 'b' to capture the background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbgModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateBackgroundSubtractorMOG2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgSubThreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_light\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0misBgCaptured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "# Camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "camera.set(10, 200)\n",
    "\n",
    "while camera.isOpened():\n",
    "    ret, frame = camera.read()\n",
    "    frame = cv2.bilateralFilter(frame, 5, 50, 100)  # smoothing filter\n",
    "    frame = cv2.flip(frame, 1)  # flip the frame horizontally\n",
    "    cv2.rectangle(frame, (int(cap_region_x_begin * frame.shape[1]), 0),\n",
    "                  (frame.shape[1], int(cap_region_y_end * frame.shape[0])), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('original', frame)\n",
    "\n",
    "    # Run once background is captured\n",
    "    if isBgCaptured == 1:\n",
    "        img = remove_background(frame)\n",
    "        img = img[0:int(cap_region_y_end * frame.shape[0]),\n",
    "              int(cap_region_x_begin * frame.shape[1]):frame.shape[1]]  # clip the ROI\n",
    "        # cv2.imshow('mask', img)\n",
    "\n",
    "        # convert the image into binary image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (blurValue, blurValue), 0)\n",
    "        # cv2.imshow('blur', blur)\n",
    "        ret, thresh = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        # Add prediction and action text to thresholded image\n",
    "        # cv2.putText(thresh, f\"Prediction: {prediction} ({score}%)\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255))\n",
    "        # cv2.putText(thresh, f\"Action: {action}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255))  # Draw the text\n",
    "        # Draw the text\n",
    "        cv2.putText(thresh, f\"Prediction: {prediction} ({score}%)\", (50, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (255, 255, 255))\n",
    "        cv2.putText(thresh, f\"Action: {action}\", (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (255, 255, 255))  # Draw the text\n",
    "        cv2.imshow('ori', thresh)\n",
    "\n",
    "        # get the contours\n",
    "        thresh1 = copy.deepcopy(thresh)\n",
    "        contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        length = len(contours)\n",
    "        maxArea = -1\n",
    "        if length > 0:\n",
    "            for i in range(length):  # find the biggest contour (according to area)\n",
    "                temp = contours[i]\n",
    "                area = cv2.contourArea(temp)\n",
    "                if area > maxArea:\n",
    "                    maxArea = area\n",
    "                    ci = i\n",
    "\n",
    "            res = contours[ci]\n",
    "            hull = cv2.convexHull(res)\n",
    "            drawing = np.zeros(img.shape, np.uint8)\n",
    "            cv2.drawContours(drawing, [res], 0, (0, 255, 0), 2)\n",
    "            cv2.drawContours(drawing, [hull], 0, (0, 0, 255), 3)\n",
    "\n",
    "        cv2.imshow('output', drawing)\n",
    "\n",
    "    # Keyboard OP\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == 27:  # press ESC to exit all windows at any time\n",
    "        break\n",
    "    elif k == ord('b'):  # press 'b' to capture the background\n",
    "        bgModel = cv2.createBackgroundSubtractorMOG2(0, bgSubThreshold)\n",
    "#         b.set_light(6, on_command)\n",
    "        time.sleep(2)\n",
    "        isBgCaptured = 1\n",
    "        print('Background captured')\n",
    "        pygame.init()\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load('/Users/brenner/1-05 Virtual Insanity.mp3')\n",
    "        pygame.mixer.music.set_volume(vol.level)\n",
    "        pygame.mixer.music.play()\n",
    "        pygame.mixer.music.set_pos(50)\n",
    "        pygame.mixer.music.pause()\n",
    "\n",
    "    elif k == ord('r'):  # press 'r' to reset the background\n",
    "        time.sleep(1)\n",
    "        bgModel = None \n",
    "        triggerSwitch = False\n",
    "        isBgCaptured = 0\n",
    "        print('Reset background')\n",
    "    elif k == 32:\n",
    "        # If space bar pressed\n",
    "        cv2.imshow('original', frame)\n",
    "        # copies 1 channel BW image to all 3 RGB channels\n",
    "        target = np.stack((thresh,) * 3, axis=-1)\n",
    "        target = cv2.resize(target, (224, 224))\n",
    "        target = target.reshape(1, 224, 224, 3)\n",
    "        prediction, score = predict_rgb_image_vgg(target)\n",
    "\n",
    "        if smart_home:\n",
    "            if prediction == 'Palm':\n",
    "                try:\n",
    "                    action = \"Lights on, music on\"\n",
    "\n",
    "                    # sonos.play()\n",
    "                    pygame.mixer.music.unpause()\n",
    "                # Turn off smart home actions if devices are not responding\n",
    "                except ConnectionError:\n",
    "                    smart_home = False\n",
    "                    pass\n",
    "\n",
    "#             elif prediction == 'Fist':\n",
    "#                 try:\n",
    "#                     action = 'Lights off, music off'\n",
    "#                     b.set_light(6, off_command)\n",
    "#                     # sonos.pause()\n",
    "#                     pygame.mixer.music.pause()\n",
    "#                 except ConnectionError:\n",
    "#                     smart_home = False\n",
    "#                     pass\n",
    "\n",
    "            elif prediction == 'L':\n",
    "                try:\n",
    "                    action = 'Volume down'\n",
    "                    # sonos.volume -= 15\n",
    "                    vol.decrease(0.2)\n",
    "                    pygame.mixer.music.set_volume(vol.level)\n",
    "                except ConnectionError:\n",
    "                    smart_home = False\n",
    "                    pass\n",
    "\n",
    "            elif prediction == 'Okay':\n",
    "                try:\n",
    "                    action = 'Volume up'\n",
    "                    # sonos.volume += 15\n",
    "                    vol.increase(0.2)\n",
    "                    pygame.mixer.music.set_volume(vol.level)\n",
    "                except ConnectionError:\n",
    "                    smart_home = False\n",
    "                    pass\n",
    "\n",
    "#             elif prediction == 'Peace':\n",
    "#                 try:\n",
    "#                     action = ''\n",
    "#                 except ConnectionError:\n",
    "#                     smart_home = False\n",
    "#                     pass\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        if save_images:\n",
    "            img_name = f\"./frames/drawings/drawing_{selected_gesture}_{img_counter}.jpg\".format(\n",
    "                img_counter)\n",
    "            cv2.imwrite(img_name, drawing)\n",
    "            print(\"{} written\".format(img_name))\n",
    "\n",
    "            img_name2 = f\"./frames/silhouettes/{selected_gesture}_{img_counter}.jpg\".format(\n",
    "                img_counter)\n",
    "            cv2.imwrite(img_name2, thresh)\n",
    "            print(\"{} written\".format(img_name2))\n",
    "\n",
    "            img_name3 = f\"./frames/masks/mask_{selected_gesture}_{img_counter}.jpg\".format(\n",
    "                img_counter)\n",
    "            cv2.imwrite(img_name3, img)\n",
    "            print(\"{} written\".format(img_name3))\n",
    "\n",
    "            img_counter += 1\n",
    "\n",
    "    elif k == ord('t'):\n",
    "\n",
    "        print('Tracker turned on.')\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Select Region of Interest (ROI)\n",
    "        r = cv2.selectROI(frame)\n",
    "\n",
    "        # Crop image\n",
    "        imCrop = frame[int(r[1]):int(r[1] + r[3]), int(r[0]):int(r[0] + r[2])]\n",
    "\n",
    "        # setup initial location of window\n",
    "        r, h, c, w = 250, 400, 400, 400\n",
    "        track_window = (c, r, w, h)\n",
    "        # set up the ROI for tracking\n",
    "        roi = imCrop\n",
    "        hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "        roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "        cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "        # Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "        term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "        while (1):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "                # apply meanshift to get the new location\n",
    "                ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "                # Draw it on image\n",
    "                pts = cv2.boxPoints(ret)\n",
    "                pts = np.int0(pts)\n",
    "                img2 = cv2.polylines(frame, [pts], True, (0, 255, 0), 2)\n",
    "                cv2.imshow('img2', img2)\n",
    "                k = cv2.waitKey(60) & 0xff\n",
    "                if k == 27:  # if ESC key\n",
    "                    break\n",
    "                else:\n",
    "                    cv2.imwrite(chr(k) + \".jpg\", img2)\n",
    "            else:\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

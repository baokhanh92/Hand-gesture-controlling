
## Hand getures
---
## [ 1. OVERVIEW ]()

**This project is based on the Kojak project: https://github.com/athena15/project_kojak**

[ **1.1 About the data**: ]() 

**1. Kaggle datatset:** Kaggle provided a large hand-gestures data could be used for this project 
![](https://i.imgur.com/eFUIMCj.jpg)

**2. Real time data + Kojak data:** the data in Kaggle will at some difference than the real life data. Let's train the model both on real-time data.
![](https://i.imgur.com/KF1jq7x.png)


[ **1.2 What you can expect in this github**: ]() 
**1. .ipynb: End to end code from processing data to build a models to predict**
**2. .py files: Code to connect trained model to control computer's volume.**

---
## [ 2. THE RESULT ]()


[ **2.1 The model**: ]() 
- Since this is a simple and clean dataset, therefore a well-build CNN architectures can predict it very well.

[ **VCG based model**: ]() 

![](https://i.imgur.com/exvGOQH.png)
![](https://i.imgur.com/hIeaXMA.png)

[ **CNN from scratch**: ]() 
![](https://i.imgur.com/ULxGR6h.png)
![](https://i.imgur.com/6ad3Bdr.png)

[ **2.2 The result**: ]() 
- When connected the model to control computer's volume, it works very well. 
![](https://i.imgur.com/qXRS1gR.png)



